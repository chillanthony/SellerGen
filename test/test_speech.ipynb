{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSML to synthesize: \n",
      "<speak version='1.0' xml:lang='zh-CN' xmlns='http://www.w3.org/2001/10/synthesis' xmlns:mstts='http://www.w3.org/2001/mstts'>\n",
      "        <voice name='zh-CN-YunxiNeural'>\n",
      "            你好您好你好。\n",
      "        </voice>\n",
      "    </speak>\n",
      "SynthesisStarted event\n",
      "Synthesizing event:\n",
      "\tAudioData: 3246 bytes\n",
      "Synthesizing event:\n",
      "\tAudioData: 3246 bytes\n",
      "Synthesizing event:\n",
      "\tAudioData: 3246 bytes\n",
      "Synthesizing event:\n",
      "\tAudioData: 3246 bytes\n",
      "Synthesizing event:\n",
      "\tAudioData: 3246 bytes\n",
      "Synthesizing event:\n",
      "\tAudioData: 3246 bytes\n",
      "Synthesizing event:\n",
      "\tAudioData: 3246 bytes\n",
      "Synthesizing event:\n",
      "\tAudioData: 3246 bytes\n",
      "Synthesizing event:\n",
      "\tAudioData: 3246 bytes\n",
      "Synthesizing event:\n",
      "\tAudioData: 3246 bytes\n",
      "Synthesizing event:\n",
      "\tAudioData: 3246 bytes\n",
      "Synthesizing event:\n",
      "\tAudioData: 3246 bytes\n",
      "Synthesizing event:\n",
      "\tAudioData: 3246 bytes\n",
      "Synthesizing event:\n",
      "\tAudioData: 3246 bytes\n",
      "Synthesizing event:\n",
      "\tAudioData: 3246 bytes\n",
      "Synthesizing event:\n",
      "\tAudioData: 3246 bytes\n",
      "Synthesizing event:\n",
      "\tAudioData: 3246 bytes\n",
      "Synthesizing event:\n",
      "\tAudioData: 2094 bytes\n",
      "VisemeReceived event:\n",
      "\tAudioOffset: 50.5ms\n",
      "\tVisemeId: 0\n",
      "WordBoundary event:\n",
      "\tBoundaryType: SpeechSynthesisBoundaryType.Word\n",
      "\tAudioOffset: 50.5ms\n",
      "\tDuration: 0:00:00.450000\n",
      "\tText: 你好\n",
      "\tTextOffset: 179\n",
      "\tWordLength: 2\n",
      "VisemeReceived event:\n",
      "\tAudioOffset: 100.5ms\n",
      "\tVisemeId: 19\n",
      "VisemeReceived event:\n",
      "\tAudioOffset: 163.0ms\n",
      "\tVisemeId: 6\n",
      "VisemeReceived event:\n",
      "\tAudioOffset: 225.5ms\n",
      "\tVisemeId: 6\n",
      "VisemeReceived event:\n",
      "\tAudioOffset: 313.0ms\n",
      "\tVisemeId: 6\n",
      "VisemeReceived event:\n",
      "\tAudioOffset: 375.5ms\n",
      "\tVisemeId: 12\n",
      "VisemeReceived event:\n",
      "\tAudioOffset: 450.5ms\n",
      "\tVisemeId: 2\n",
      "VisemeReceived event:\n",
      "\tAudioOffset: 513.0ms\n",
      "\tVisemeId: 8\n",
      "WordBoundary event:\n",
      "\tBoundaryType: SpeechSynthesisBoundaryType.Word\n",
      "\tAudioOffset: 525.5ms\n",
      "\tDuration: 0:00:00.225000\n",
      "\tText: 您好\n",
      "\tTextOffset: 181\n",
      "\tWordLength: 2\n",
      "WordBoundary event:\n",
      "\tBoundaryType: SpeechSynthesisBoundaryType.Sentence\n",
      "\tAudioOffset: 50.5ms\n",
      "\tDuration: 0:00:01.637500\n",
      "\tText: 你好您好你好。\n",
      "\tTextOffset: 179\n",
      "\tWordLength: 7\n",
      "VisemeReceived event:\n",
      "\tAudioOffset: 550.5ms\n",
      "\tVisemeId: 0\n",
      "VisemeReceived event:\n",
      "\tAudioOffset: 575.5ms\n",
      "\tVisemeId: 19\n",
      "VisemeReceived event:\n",
      "\tAudioOffset: 588.0ms\n",
      "\tVisemeId: 6\n",
      "VisemeReceived event:\n",
      "\tAudioOffset: 600.5ms\n",
      "\tVisemeId: 6\n",
      "VisemeReceived event:\n",
      "\tAudioOffset: 625.5ms\n",
      "\tVisemeId: 19\n",
      "VisemeReceived event:\n",
      "\tAudioOffset: 675.5ms\n",
      "\tVisemeId: 12\n",
      "VisemeReceived event:\n",
      "\tAudioOffset: 725.5ms\n",
      "\tVisemeId: 2\n",
      "WordBoundary event:\n",
      "\tBoundaryType: SpeechSynthesisBoundaryType.Word\n",
      "\tAudioOffset: 750.5ms\n",
      "\tDuration: 0:00:00.425000\n",
      "\tText: 你好\n",
      "\tTextOffset: 183\n",
      "\tWordLength: 2\n",
      "VisemeReceived event:\n",
      "\tAudioOffset: 763.0ms\n",
      "\tVisemeId: 8\n",
      "VisemeReceived event:\n",
      "\tAudioOffset: 800.5ms\n",
      "\tVisemeId: 19\n",
      "VisemeReceived event:\n",
      "\tAudioOffset: 819.25ms\n",
      "\tVisemeId: 6\n",
      "VisemeReceived event:\n",
      "\tAudioOffset: 838.0ms\n",
      "\tVisemeId: 6\n",
      "VisemeReceived event:\n",
      "\tAudioOffset: 875.5ms\n",
      "\tVisemeId: 6\n",
      "VisemeReceived event:\n",
      "\tAudioOffset: 925.5ms\n",
      "\tVisemeId: 12\n",
      "VisemeReceived event:\n",
      "\tAudioOffset: 988.0ms\n",
      "\tVisemeId: 2\n",
      "VisemeReceived event:\n",
      "\tAudioOffset: 1038.0ms\n",
      "\tVisemeId: 8\n",
      "WordBoundary event:\n",
      "\tBoundaryType: SpeechSynthesisBoundaryType.Punctuation\n",
      "\tAudioOffset: 1175.5ms\n",
      "\tDuration: 0:00:00.112500\n",
      "\tText: 。\n",
      "\tTextOffset: 185\n",
      "\tWordLength: 1\n",
      "VisemeReceived event:\n",
      "\tAudioOffset: 1225.5ms\n",
      "\tVisemeId: 0\n",
      "SynthesisCompleted event:\n",
      "\tAudioData: 56494 bytes\n",
      "\tAudioDuration: 0:00:01.687000\n",
      "SynthesizingAudioCompleted result\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "def speech_synthesizer_bookmark_reached_cb(evt: speechsdk.SessionEventArgs):\n",
    "    print('BookmarkReached event:')\n",
    "    print('\\tAudioOffset: {}ms'.format((evt.audio_offset + 5000) / 10000))\n",
    "    print('\\tText: {}'.format(evt.text))\n",
    "\n",
    "def speech_synthesizer_synthesis_canceled_cb(evt: speechsdk.SessionEventArgs):\n",
    "    print('SynthesisCanceled event')\n",
    "\n",
    "def speech_synthesizer_synthesis_completed_cb(evt: speechsdk.SessionEventArgs):\n",
    "    print('SynthesisCompleted event:')\n",
    "    print('\\tAudioData: {} bytes'.format(len(evt.result.audio_data)))\n",
    "    print('\\tAudioDuration: {}'.format(evt.result.audio_duration))\n",
    "\n",
    "def speech_synthesizer_synthesis_started_cb(evt: speechsdk.SessionEventArgs):\n",
    "    print('SynthesisStarted event')\n",
    "\n",
    "def speech_synthesizer_synthesizing_cb(evt: speechsdk.SessionEventArgs):\n",
    "    print('Synthesizing event:')\n",
    "    print('\\tAudioData: {} bytes'.format(len(evt.result.audio_data)))\n",
    "\n",
    "def speech_synthesizer_viseme_received_cb(evt: speechsdk.SessionEventArgs):\n",
    "    print('VisemeReceived event:')\n",
    "    print('\\tAudioOffset: {}ms'.format((evt.audio_offset + 5000) / 10000))\n",
    "    print('\\tVisemeId: {}'.format(evt.viseme_id))\n",
    "\n",
    "def speech_synthesizer_word_boundary_cb(evt: speechsdk.SessionEventArgs):\n",
    "    print('WordBoundary event:')\n",
    "    print('\\tBoundaryType: {}'.format(evt.boundary_type))\n",
    "    print('\\tAudioOffset: {}ms'.format((evt.audio_offset + 5000) / 10000))\n",
    "    print('\\tDuration: {}'.format(evt.duration))\n",
    "    print('\\tText: {}'.format(evt.text))\n",
    "    print('\\tTextOffset: {}'.format(evt.text_offset))\n",
    "    print('\\tWordLength: {}'.format(evt.word_length))\n",
    "\n",
    "# This example requires environment variables named \"SPEECH_KEY\" and \"SPEECH_REGION\"\n",
    "speech_config = speechsdk.SpeechConfig(subscription=os.environ.get('SPEECH_KEY'), region=os.environ.get('SPEECH_REGION'))\n",
    "\n",
    "# Required for WordBoundary event sentences.\n",
    "speech_config.set_property(property_id=speechsdk.PropertyId.SpeechServiceResponse_RequestSentenceBoundary, value='true')\n",
    "\n",
    "audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\n",
    "speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "# Subscribe to events\n",
    "speech_synthesizer.bookmark_reached.connect(speech_synthesizer_bookmark_reached_cb)\n",
    "speech_synthesizer.synthesis_canceled.connect(speech_synthesizer_synthesis_canceled_cb)\n",
    "speech_synthesizer.synthesis_completed.connect(speech_synthesizer_synthesis_completed_cb)\n",
    "speech_synthesizer.synthesis_started.connect(speech_synthesizer_synthesis_started_cb)\n",
    "speech_synthesizer.synthesizing.connect(speech_synthesizer_synthesizing_cb)\n",
    "speech_synthesizer.viseme_received.connect(speech_synthesizer_viseme_received_cb)\n",
    "speech_synthesizer.synthesis_word_boundary.connect(speech_synthesizer_word_boundary_cb)\n",
    "\n",
    "# The language of the voice that speaks.\n",
    "\n",
    "ssml = \"\"\"<speak version='1.0' xml:lang='zh-CN' xmlns='http://www.w3.org/2001/10/synthesis' xmlns:mstts='http://www.w3.org/2001/mstts'>\n",
    "        <voice name='zh-CN-YunxiNeural'>\n",
    "            你好您好你好。\n",
    "        </voice>\n",
    "    </speak>\"\"\"\n",
    "\n",
    "# Synthesize the SSML\n",
    "print(\"SSML to synthesize: \\r\\n{}\".format(ssml))\n",
    "speech_synthesis_result = speech_synthesizer.speak_ssml_async(ssml).get()\n",
    "\n",
    "if speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "    print(\"SynthesizingAudioCompleted result\")\n",
    "elif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n",
    "    cancellation_details = speech_synthesis_result.cancellation_details\n",
    "    print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n",
    "    if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "        if cancellation_details.error_details:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "            print(\"Did you set the speech resource key and region values?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "video",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
